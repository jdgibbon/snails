{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import matplotlib and PyTorch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 4D pytorch tensor, the 4 dimensions (labelled 0 to 3) are:\n",
    "\n",
    "0. Batch size\n",
    "1. Number of channels, e.g. 1 for grayscale, 3 for RGB \n",
    "2. Height of each image in pixels.\n",
    "3. Width of each image in pixels.\n",
    "\n",
    "We need certain rotations and flips to be available to us, so we define functions:\n",
    "\n",
    "rotate_180(x): to be used to add invariance with respect to 180 degree rotation. \n",
    "Reverses the 3rd and 4th dimensions ([2,3]). \n",
    "x_flip(x): flips left-right. Flips the 4th dimension. \n",
    "y_flip(x): flips top-bottom. Flips the 3rd dimension. \n",
    "\n",
    "x is our tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_180(x):\n",
    "    return torch.flip(x,[2,3])\n",
    "\n",
    "def x_flip(x):\n",
    "    return torch.flip(x,[3])\n",
    "\n",
    "def y_flip(x):\n",
    "    return torch.flip(x,[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are looking to form 2 groups of test/train datasets (non-modified chiral and \n",
    "50% flipped achiral), we need to do some preprocessing of our data into these sets.\n",
    "\n",
    "These 2 groups will be named as follows (taking inspiration on from Dr Lester's \n",
    "previous work):\n",
    "\n",
    "1. S\n",
    "2. SLR\n",
    "\n",
    "where 'S' is for snail, and 'LR' (Left-Right) labels the achiral group.\n",
    "\n",
    "We define the Group class, which will allow us reference different aspects of \n",
    "the objects we are dealing with, and to view our results in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group:\n",
    "    def __init__(self,name, train=True, trainloader=None, testloader=None, net=None):\n",
    "        self.name=name\n",
    "        self.train=train\n",
    "        if trainloader is not None:\n",
    "            self.set_trainloader(trainloader)\n",
    "        if testloader is not None:\n",
    "            self.set_testloader(testloader)\n",
    "        if net is not None:\n",
    "            self.set_net(net)\n",
    "\n",
    "    def return_test_images(self):\n",
    "        dataiter1 = iter(self.testloader)\n",
    "        images, labels = next(dataiter1)\n",
    "        images, labels = images.to(mps_device), labels.to(mps_device)\n",
    "        return images\n",
    "\n",
    "    def return_train_images(self):\n",
    "        dataiter2 = iter(self.trainloader)\n",
    "        images, labels = next(dataiter2)\n",
    "        images, labels = images.to(mps_device), labels.to(mps_device)\n",
    "        return images\n",
    "\n",
    "    def set_trainloader(self, loader):\n",
    "        self.trainloader = loader\n",
    "\n",
    "    def set_testloader(self, loader):\n",
    "        self.testloader = loader\n",
    "\n",
    "    def set_net(self, net):\n",
    "        self.net = net\n",
    "        import torch.optim as optim\n",
    "        self.optimizer = optim.SGD(self.net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    def parity_calculations(self, net_outputs, test, output):\n",
    "        from math import sqrt\n",
    "        num_positives=torch.count_nonzero(torch.gt(net_outputs,0).int()).item()\n",
    "        num_negatives=torch.count_nonzero(torch.lt(net_outputs,0).int()).item()\n",
    "        num_zeros=torch.count_nonzero(torch.eq(net_outputs,0).int()).item()\n",
    "        num_total=num_positives+num_zeros+num_negatives\n",
    "        poisson_p=num_positives/num_total\n",
    "        poisson_q=1.0-poisson_p\n",
    "        poisson_mean = num_total*poisson_p\n",
    "        poisson_variance = num_total*poisson_p*poisson_q\n",
    "        poisson_sd=sqrt(poisson_variance)\n",
    "\n",
    "        fractional_mean = poisson_mean/num_total\n",
    "        fractional_sd = poisson_sd/num_total\n",
    "\n",
    "        if output == True:  \n",
    "            print(\"On\",(\"test\" if test else \"train\"),\": Positive Fraction \",100*fractional_mean,\"+-\",100*fractional_sd,\"%\")\n",
    "        elif output == False:\n",
    "            print(100*fractional_mean,100*fractional_sd)\n",
    "\n",
    "\n",
    "    def output_values(self, output, test):\n",
    "        if test == True:\n",
    "            self.parity_calculations(self.net(self.return_test_images()), test, output)\n",
    "        elif test == False:\n",
    "            self.parity_calculations(self.net(self.return_train_images()), test, output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the test and train datasets:\n",
    "\n",
    "Now, to generate a tensor from the image input. We will take the image input and \n",
    "put it through 4 transforms sequentially using transforms.Compose()\n",
    "\n",
    "transforms.ToTensor(): converts the image into 3 RGB colour channels (or 1 \n",
    "greyscale channel)\n",
    "transforms.Normalise(mean, std): normalises the tensor according to mean and s.d. parameters\n",
    "transforms.Resize(x): resizes the image such that the shortest side is now x pixels\n",
    "Transforms.CentreCrop(x): crops the image in a square at the centre with side length x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.5s\n",
    "\n",
    "#normal:\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406],  std=[0.229, 0.224, 0.225]), transforms.Resize(64, antialias=True), transforms.CenterCrop(64)])\n",
    "\n",
    "#for greyscale\n",
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5],  std=[0.5, 0.5, 0.5]), transforms.Resize(64, antialias=True), transforms.CenterCrop(64)])\n",
    "\n",
    "\n",
    "folder_name = \"model\"\n",
    "\n",
    "test_path = \"/Users/jamesgibbon/Library/CloudStorage/OneDrive-UniversityofCambridge/Natural Sciences/Part III/Project/\" + folder_name + \"/test\"\n",
    "train_path = \"/Users/jamesgibbon/Library/CloudStorage/OneDrive-UniversityofCambridge/Natural Sciences/Part III/Project/\" + folder_name + \"/train\"\n",
    "\n",
    "testset = ImageFolder(root=test_path, transform=transform)\n",
    "print(f\"Number of test images: {len(testset)}\")\n",
    "\n",
    "trainset = ImageFolder(root=train_path, transform=transform)\n",
    "print(f\"Number of training images: {len(trainset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 mins for 125,000 images (17s per 10000)\n",
    "\n",
    "def flip_dataset(dataset):\n",
    "    flip_transform = transforms.RandomHorizontalFlip(p=1.0)\n",
    "    flipped_dataset = []\n",
    "    count = 0\n",
    "\n",
    "    for image, label in dataset:\n",
    "        if np.random.binomial(1, 0.5):\n",
    "            image = flip_transform(image)\n",
    "        \n",
    "        flipped_dataset.append((image, label))\n",
    "        count +=1\n",
    "        if count%1000 == 0:\n",
    "            print(count, \"Done!\")\n",
    "\n",
    "\n",
    "    \n",
    "    return flipped_dataset\n",
    "\n",
    "testset_SLR = flip_dataset(testset)\n",
    "trainset_SLR = flip_dataset(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "factor = len(testset)/2447\n",
    "#factor = 1\n",
    "\n",
    "\n",
    "print(\"Factor is \", factor)\n",
    "\n",
    "trainloader_S = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)  \n",
    "testloader_S = torch.utils.data.DataLoader(testset, batch_size=int(len(testset)/factor), shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "trainloader_SLR = torch.utils.data.DataLoader(trainset_SLR, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4)\n",
    "testloader_SLR = torch.utils.data.DataLoader(testset_SLR, batch_size=int(len(testset)/factor), shuffle=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "print(trainloader_S.batch_size,testloader_S.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"S\" : Group(\"S\", train=False, trainloader=trainloader_S, testloader=testloader_S),\n",
    "    \"SLR\" : Group(\"SLR\", train=False, trainloader=trainloader_SLR, testloader=testloader_SLR),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK TRAINLOADER LENGTH\n",
    "\n",
    "for name, group in groups.items():\n",
    "    num_batches = len(group.trainloader)\n",
    "    batch_size = group.trainloader.batch_size\n",
    "    num_images = num_batches * batch_size\n",
    "    print(f\"Number of images in {name}: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "#PLOT IMAGES - 25s\n",
    "for name, group in groups.items():\n",
    "    dataiter = iter(group.trainloader)\n",
    "    print(name, \"(train)\")\n",
    "    images, labels = next(dataiter)\n",
    "    imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.tensor_size=torch.tensor([64,64]) #IMAGE SIZE\n",
    "\n",
    "        self.kernel_1_size = (5,5)\n",
    "        self.kernel_2_size = (5,5)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, self.kernel_1_size,1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, self.kernel_1_size,1)\n",
    "        self.fc1 = nn.Linear(32 * 13 * 13, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        answer = self.forward_worker(x)\n",
    "        answer = answer + self.forward_worker(rotate_180(x))\n",
    "        answer = answer - self.forward_worker(y_flip(x))\n",
    "        answer = answer - self.forward_worker(x_flip(x))\n",
    "        return answer/4.0\n",
    "\n",
    "    def forward_worker(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        #Flatten x along \"channel\" dimension - we will create a 2D tensor with dimensions\n",
    "        #(batch size, number of channels * height * width)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = torch.sum(x, dim=1)\n",
    "        return x\n",
    "\n",
    "model = Net().to(mps_device)\n",
    "print(model)\n",
    "\n",
    "for group in groups.values():\n",
    "    group.set_net(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function that outputs positive fraction values for a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_fraction(groupname, message, attempts=1, output = True, test = True):\n",
    "    group = groups[groupname]\n",
    "    for _ in range(attempts):\n",
    "        print(message,group.name)\n",
    "        group.output_values(output,test)\n",
    "            \n",
    "        print()\n",
    "\n",
    "#before training - 14s\n",
    "#positive_fraction(\"S\",\"Before Training\",1, output = True, test = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training! We will do this group-wise, using: https://gist.github.com/llSourcell/a0c1185e1b426ae598bde2be8c321a95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_group(group, no_of_epochs):  \n",
    "\n",
    "    print('Start Training',group.name)\n",
    "    #Output current performance\n",
    "    #group.output_values()\n",
    "    print('\\n')\n",
    "    for epoch in range(no_of_epochs):\n",
    "        #Set loss to 0\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(group.trainloader, 0):\n",
    "            #Import data\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(mps_device), labels.to(mps_device)\n",
    "            \n",
    "            #Zero parameter gradients\n",
    "            group.optimizer.zero_grad()\n",
    "\n",
    "            #Calculate std and mean of the outputs of the net\n",
    "            std = torch.std(group.net(inputs))\n",
    "            mean = torch.mean(group.net(inputs))\n",
    "              \n",
    "            #we want to MAXIMISE mean/std, so we want to MINIMISE -mean/std\n",
    "            loss = -mean/std\n",
    "\n",
    "            #enforce the minimisation of the loss, and update the parameters \n",
    "            #based on the gradients computed in backpropagation (using SGD)\n",
    "            loss.backward()\n",
    "            group.optimizer.step()\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += (-loss).item()\n",
    "            print_freq=100\n",
    "            if i % print_freq == print_freq-1:\n",
    "                print('[Epoch %d, Batch %d] loss: %.3f' %(epoch + 1, i + 1, running_loss/print_freq ))\n",
    "                running_loss = 0.0\n",
    "                #group.output_values()\n",
    "        \n",
    "        # model_dir = '/Users/jamesgibbon/Library/CloudStorage/OneDrive-UniversityofCambridge/Natural Sciences/Part III/Project/Hands Removed Helicoid/'        \n",
    "        # epoch_plus_1 = str(1 + epoch)\n",
    "        # run_identifier = \"_\" + epoch_plus_1 + \"E_BS16_NH_1\"\n",
    "        # PATH = model_dir+group.name+run_identifier+'.pth'\n",
    "        # torch.save(group.net.state_dict(),PATH)\n",
    "        #group.output_values(output = True, test = True)\n",
    "        print(\"Epoch \", epoch+1, \" Done!\" )\n",
    "        print('\\n')\n",
    "    print('Finished Training',group.name)    \n",
    "    #group.output_values(output = False, test = True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save(extension, no_of_epochs):\n",
    "\n",
    "    for name, group in groups.items():  \n",
    "        \n",
    "        train_group(group, no_of_epochs)\n",
    "        \n",
    "        folder_name = \"BLACKWHITEHRH\"\n",
    "        model_dir = \"/Users/jamesgibbon/Library/CloudStorage/OneDrive-UniversityofCambridge/Natural Sciences/Part III/Project/\" + folder_name + \"/\"\n",
    "        PATH = model_dir+name+extension+'.pth'\n",
    "        \n",
    "        torch.save(group.net.state_dict(),PATH)\n",
    "        \n",
    "def load(groupname, extension):\n",
    "    folder_name = \"BLACKWHITEHRH\"\n",
    "    model_dir = \"/Users/jamesgibbon/Library/CloudStorage/OneDrive-UniversityofCambridge/Natural Sciences/Part III/Project/\" + folder_name + \"/\"\n",
    "    \n",
    "    group = groups[groupname]\n",
    "    name = group.name\n",
    "    NAME = name + extension + '.pth'\n",
    "    group.net.load_state_dict(torch.load(model_dir+NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.has_mps)\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN - takes 2 minutes per dataset (S and SLR) per epoch, running through 100,000 images\n",
    "train_and_save(\"_END15E_BS64_BLACKWHITEHRH\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_no = 15\n",
    "\n",
    "for groupname in [\"S\",\"SLR\"]:\n",
    "    print(\"Batch Size is\", testloader_S.batch_size)\n",
    "    load(groupname,\"_END\"+str(epoch_no)+\"E_BS64_BLACKWHITEHRH\")\n",
    "    positive_fraction(groupname, \"After training for \" + str(epoch_no) + \" Epochs:\", attempts = int(factor), output = False, test = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    for groupname in [\"S\",\"SLR\"]:\n",
    "        load(groupname,\"_\"+str(1+i)+\"E_BS16_NH_1\")\n",
    "        positive_fraction(groupname, \"(TESTSET) After training for \" + str(i+1) + \" Epochs:\", attempts = 1, output = False, test = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75bd3a244af9dfcc29ae492a0c2294e19ee7b7f2e7c4a248126ab76dce85a31a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
